{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2575a2eb",
   "metadata": {},
   "source": [
    "# Setup Models\n",
    "\n",
    "This code block downloads Sentence-BERT models and loads them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a36c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model_names = [\n",
    "    # Official models\n",
    "    \"all-mpnet-base-v2\",\n",
    "    \"multi-qa-mpnet-base-dot-v1\",\n",
    "    \"all-distilroberta-v1\",\n",
    "    \"all-MiniLM-L12-v2\",\n",
    "    \"multi-qa-distilbert-cos-v1\",\n",
    "    \"all-MiniLM-L6-v2\",\n",
    "    \"multi-qa-MiniLM-L6-cos-v1\",\n",
    "    \"paraphrase-multilingual-mpnet-base-v2\",\n",
    "    \"paraphrase-albert-small-v2\",\n",
    "    \"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    \"paraphrase-MiniLM-L3-v2\",\n",
    "    \"distiluse-base-multilingual-cased-v1\",\n",
    "    \"distiluse-base-multilingual-cased-v2\",\n",
    "    # Third-party models\n",
    "    \"nikcheerla/nooks-amd-detection-v2-full\",\n",
    "    \"jhgan/ko-sroberta-multitask\",\n",
    "    \"ceggian/sbert_pt_reddit_softmax_512\",\n",
    "    \"BlueAvenir/sti_security_class_model\",\n",
    "    \"jhgan/ko-sbert-sts\",\n",
    "    \"nikcheerla/nooks-amd-detection-realtime\",\n",
    "    \"sentence-transformers/LaBSE\",\n",
    "    \"kwoncho/ko-sroberta-multitask-suspicious\"\n",
    "]\n",
    "model_max_seqs = [\n",
    "    # Official models\n",
    "    384,\n",
    "    512,\n",
    "    512,\n",
    "    256,\n",
    "    512,\n",
    "    256,\n",
    "    512,\n",
    "    128,\n",
    "    256,\n",
    "    128,\n",
    "    128,\n",
    "    128,\n",
    "    128,\n",
    "    # Third-party models\n",
    "    512,\n",
    "    512,\n",
    "    512,\n",
    "    512,\n",
    "    512,\n",
    "    512,\n",
    "    512,\n",
    "    512\n",
    "]\n",
    "\n",
    "def makeModel(model_name, max_seq_len):\n",
    "    print(model_name)\n",
    "    model = SentenceTransformer(model_name)\n",
    "    model.max_seq_length = max_seq_len\n",
    "    return model\n",
    "\n",
    "models = list()\n",
    "for i in range(0, len(model_names)):\n",
    "    new_model = [model_names[i]]\n",
    "    new_model.append(makeModel(model_names[i], model_max_seqs[i]))\n",
    "    models.append(new_model)\n",
    "    \n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fba249",
   "metadata": {},
   "source": [
    "# Gather Data\n",
    "\n",
    "This code block loads necessary data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6359f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def readData(file_name):\n",
    "    data = list()\n",
    "    header = None\n",
    "    with open(file_name, \"r\") as f:\n",
    "        csv_reader = csv.reader(f, delimiter=\",\", quotechar=\"\\\"\", quoting=csv.QUOTE_MINIMAL)\n",
    "        header = next(csv_reader) # Skip header row\n",
    "        for line in csv_reader:\n",
    "            data.append(line)\n",
    "            \n",
    "    return data, header\n",
    "\n",
    "data_files = [\n",
    "    \"data/human_errors.csv\",           # Human Errors from GitHub and Interviews\n",
    "    \"data/these_descriptions.csv\",     # THESE Categories (S01, S02, ...)\n",
    "    \"data/these_type_descriptions.csv\" # THESE Types (Slip, Lapse, Mistake)\n",
    "    # Comment out the above 2 lines and uncomment the next 2 lines to run this\n",
    "    # experiment with improved THESE descriptions\n",
    "    # \"data/these_descriptions_v4.csv\"\n",
    "    # \"data/these_type_descriptions_v4.csv\"\n",
    "]\n",
    "\n",
    "errors, errors_header = readData(data_files[0])\n",
    "errors_noaps = errors[202:] # Remove Apologies\n",
    "categories, categories_header = readData(data_files[1])\n",
    "categories.pop(-1) # Remove \"Other\"\n",
    "types, types_header = readData(data_files[2])\n",
    "\n",
    "print(len(errors))       # Expecting 368\n",
    "print(len(errors_noaps)) # Expecting 166\n",
    "print(len(categories))   # Expecting 31\n",
    "print(len(types))        # Expecting 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ad8b3",
   "metadata": {},
   "source": [
    "# Compute Embeddings\n",
    "\n",
    "This code block computes embeddings for our data. Change `cleantext=True` to `cleantext=False` to run the experiment without preprocessing. This takes about 10 minutes to run with 16 CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import re\n",
    "\n",
    "RE_PUNCT = re.compile(r\"[\\.,:;?!]\")\n",
    "RE_WHITESPACE = re.compile(r\"[\\n\\r\\t\\v\\f]\") # everything but regular spaces\n",
    "RE_DUPLICATE_SPACES = re.compile(r\"[\\s]+\")\n",
    "\n",
    "error_embeddings = list()\n",
    "category_embeddings = list()\n",
    "type_embeddings = list()\n",
    "\n",
    "def cleanup(sentence):\n",
    "    sent = RE_PUNCT.sub(\" \", sentence.lower())\n",
    "    sent = RE_WHITESPACE.sub(\" \", sent)\n",
    "    sent = RE_DUPLICATE_SPACES.sub(\" \", sent)\n",
    "    return sent\n",
    "\n",
    "def computeEmbeddings(models, data, comment_index, cleantext=True):\n",
    "    if cleantext:\n",
    "        sentences = [cleanup(d[comment_index]) for d in data]\n",
    "    else:\n",
    "        sentences = [d[comment_index] for d in data]\n",
    "    embeddings = list()\n",
    "    for model in models:\n",
    "        embeddings.append(model[1].encode(sentences, convert_to_tensor=True))\n",
    "        \n",
    "    return embeddings, sentences\n",
    "\n",
    "error_embeddings, error_sentences = computeEmbeddings(models, errors, 1)\n",
    "error_noaps_embeddings, error_noaps_sentences = computeEmbeddings(models, errors_noaps, 1)\n",
    "category_embeddings, category_sentences = computeEmbeddings(models, categories, 3)\n",
    "type_embeddings, type_sentences = computeEmbeddings(models, types, 1)\n",
    "\n",
    "print(len(error_embeddings))       # Expecting 20\n",
    "print(len(error_noaps_embeddings)) # Expecting 20\n",
    "print(len(category_embeddings))    # Expecting 20\n",
    "print(len(type_embeddings))        # Expecting 20\n",
    "\n",
    "print(len(error_embeddings[0]))       # Expecting 368\n",
    "print(len(error_noaps_embeddings[0])) # Expecting 166\n",
    "print(len(category_embeddings[0]))    # Expecting 31\n",
    "print(len(type_embeddings[0]))        # Expecting 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a152d",
   "metadata": {},
   "source": [
    "# Multi-Class\n",
    "\n",
    "This section runs multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34698d55",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31005e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_labels = [e[2] for e in errors]\n",
    "error_noaps_labels = [e[2] for e in errors_noaps]\n",
    "category_labels = [c[0] for c in categories]\n",
    "type_labels = [t[0] for t in types]\n",
    "\n",
    "category_assigned = list()\n",
    "category_type_assigned = list()\n",
    "type_assigned = list()\n",
    "\n",
    "def compareLabels(model_index, err_embeddings, err_sentences, label_embeddings, label_sentences, labels):\n",
    "    assigned_labels = list()\n",
    "    for i in range(0, len(err_embeddings[model_index])):\n",
    "        cosine_scores = list()\n",
    "        for j in range(0, len(label_embeddings[model_index])):\n",
    "            # Compute cosine similarity between a single error sentence and a single label sentence\n",
    "            cosine_scores.append(util.cos_sim(\n",
    "                err_embeddings[model_index][i],\n",
    "                label_embeddings[model_index][j]\n",
    "            ))\n",
    "        \n",
    "        max_index = -999\n",
    "        max_value = -999\n",
    "        for k in range(0, len(cosine_scores)):\n",
    "            if cosine_scores[k] >= max_value:\n",
    "                max_value = cosine_scores[k]\n",
    "                max_index = k\n",
    "                \n",
    "        assigned_labels.append(labels[max_index])\n",
    "        \n",
    "    return assigned_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314f79b",
   "metadata": {},
   "source": [
    "## Confusion Matrix w/ Apologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad291e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def confusionMatrix(assigned_labels, error_labels):\n",
    "    conf_mat = [\n",
    "        [0, 0, 0], #Assigned-Actual: Slip-Slip, Slip-Lapse, Slip-Mistake\n",
    "        [0, 0, 0], #Assigned-Actual: Lapse-Slip, Lapse-Lapse, Lapse-Mistake\n",
    "        [0, 0, 0]  #Assigned-Actual: Mistake-Slip, Mistake-Lapse, Mistake-Mistake\n",
    "    ]\n",
    "    for i in range(0, len(error_labels)):\n",
    "        #print(i)\n",
    "        if error_labels[i][0] == \"S\":\n",
    "            if assigned_labels[i][0] == \"S\":\n",
    "                conf_mat[0][0] += 1\n",
    "            elif assigned_labels[i][0] == \"L\":\n",
    "                conf_mat[1][0] += 1\n",
    "            elif assigned_labels[i][0] == \"M\":\n",
    "                conf_mat[2][0] += 1\n",
    "        elif error_labels[i][0] == \"L\":\n",
    "            if assigned_labels[i][0] == \"S\":\n",
    "                conf_mat[0][1] += 1\n",
    "            elif assigned_labels[i][0] == \"L\":\n",
    "                conf_mat[1][1] += 1\n",
    "            elif assigned_labels[i][0] == \"M\":\n",
    "                conf_mat[2][1] += 1\n",
    "        elif error_labels[i][0] == \"M\":\n",
    "            if assigned_labels[i][0] == \"S\":\n",
    "                conf_mat[0][2] += 1\n",
    "            elif assigned_labels[i][0] == \"L\":\n",
    "                conf_mat[1][2] += 1\n",
    "            elif assigned_labels[i][0] == \"M\":\n",
    "                conf_mat[2][2] += 1\n",
    "                \n",
    "    return conf_mat\n",
    "    \n",
    "def calcTP(conf_mat, label):\n",
    "    if label == \"SLIP\":\n",
    "        return conf_mat[0][0]\n",
    "    elif label == \"LAPSE\":\n",
    "        return conf_mat[1][1]\n",
    "    elif label == \"MISTAKE\":\n",
    "        return conf_mat[2][2]\n",
    "\n",
    "def calcTN(conf_mat, label):\n",
    "    if label == \"SLIP\":\n",
    "        return conf_mat[1][1] + conf_mat[1][2] + conf_mat[2][1] + conf_mat[2][2]\n",
    "    elif label == \"LAPSE\":\n",
    "        return conf_mat[0][0] + conf_mat[0][2] + conf_mat[2][0] + conf_mat[2][2]\n",
    "    elif label == \"MISTAKE\":\n",
    "        return conf_mat[0][0] + conf_mat[0][1] + conf_mat[1][0] + conf_mat[1][1]\n",
    "\n",
    "def calcFP(conf_mat, label):\n",
    "    if label == \"SLIP\":\n",
    "        return conf_mat[0][1] + conf_mat[0][2]\n",
    "    elif label == \"LAPSE\":\n",
    "        return conf_mat[1][0] + conf_mat[1][2]\n",
    "    elif label == \"MISTAKE\":\n",
    "        return conf_mat[2][0] + conf_mat[2][1]\n",
    "\n",
    "def calcFN(conf_mat, label):\n",
    "    if label == \"SLIP\":\n",
    "        return conf_mat[1][0] + conf_mat[2][0]\n",
    "    elif label == \"LAPSE\":\n",
    "        return conf_mat[0][1] + conf_mat[2][1]\n",
    "    elif label == \"MISTAKE\":\n",
    "        return conf_mat[0][2] + conf_mat[1][2]\n",
    "    \n",
    "def calcPrecision(tp, fp):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def calcRecall(tp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def calcF1(tp, fp, fn):\n",
    "    return (2 * tp) / ((2 * tp) + fp + fn)\n",
    "    \n",
    "for model_index in range(0, len(models)):\n",
    "    assigned_labels = compareLabels(\n",
    "        model_index,\n",
    "        error_embeddings,\n",
    "        error_sentences,\n",
    "        type_embeddings,\n",
    "        type_sentences,\n",
    "        type_labels\n",
    "    )\n",
    "    conf_mat = confusionMatrix(assigned_labels, error_labels)\n",
    "    # Slips\n",
    "    tp = calcTP(conf_mat, \"SLIP\")\n",
    "    fp = calcFP(conf_mat, \"SLIP\")\n",
    "    tn = calcTN(conf_mat, \"SLIP\")\n",
    "    fn = calcFN(conf_mat, \"SLIP\")\n",
    "    precision = round(calcPrecision(tp, fp), 3)\n",
    "    recall = round(calcRecall(tp, fn), 3)\n",
    "    f1 = round(calcF1(tp, fp, fn), 3)\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(fp,tp,fn,tn,precision,recall,f1))\n",
    "    \n",
    "print(\"\\n\")\n",
    "    \n",
    "for model_index in range(0, len(models)):\n",
    "    assigned_labels = compareLabels(\n",
    "        model_index,\n",
    "        error_embeddings,\n",
    "        error_sentences,\n",
    "        type_embeddings,\n",
    "        type_sentences,\n",
    "        type_labels\n",
    "    )\n",
    "    conf_mat = confusionMatrix(assigned_labels, error_labels)\n",
    "    # Lapses\n",
    "    tp = calcTP(conf_mat, \"LAPSE\")\n",
    "    fp = calcFP(conf_mat, \"LAPSE\")\n",
    "    tn = calcTN(conf_mat, \"LAPSE\")\n",
    "    fn = calcFN(conf_mat, \"LAPSE\")\n",
    "    precision = round(calcPrecision(tp, fp), 3)\n",
    "    recall = round(calcRecall(tp, fn), 3)\n",
    "    f1 = round(calcF1(tp, fp, fn), 3)\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(fp,tp,fn,tn,precision,recall,f1))\n",
    "    \n",
    "print(\"\\n\")\n",
    "    \n",
    "for model_index in range(0, len(models)):\n",
    "    assigned_labels = compareLabels(\n",
    "        model_index,\n",
    "        error_embeddings,\n",
    "        error_sentences,\n",
    "        type_embeddings,\n",
    "        type_sentences,\n",
    "        type_labels\n",
    "    )\n",
    "    conf_mat = confusionMatrix(assigned_labels, error_labels)\n",
    "    # Mistakes\n",
    "    tp = calcTP(conf_mat, \"MISTAKE\")\n",
    "    fp = calcFP(conf_mat, \"MISTAKE\")\n",
    "    tn = calcTN(conf_mat, \"MISTAKE\")\n",
    "    fn = calcFN(conf_mat, \"MISTAKE\")\n",
    "    precision = round(calcPrecision(tp, fp), 3)\n",
    "    recall = round(calcRecall(tp, fn), 3)\n",
    "    f1 = round(calcF1(tp, fp, fn), 3)\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(fp,tp,fn,tn,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee300be",
   "metadata": {},
   "source": [
    "## Confusion Matrix w/o Apologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_index in range(0, len(models)):\n",
    "    assigned_labels = compareLabels(\n",
    "        model_index,\n",
    "        error_noaps_embeddings,\n",
    "        error_noaps_sentences,\n",
    "        type_embeddings,\n",
    "        type_sentences,\n",
    "        type_labels\n",
    "    )\n",
    "    conf_mat = confusionMatrix(assigned_labels, error_noaps_labels)\n",
    "    # Slips\n",
    "    tp = calcTP(conf_mat, \"SLIP\")\n",
    "    fp = calcFP(conf_mat, \"SLIP\")\n",
    "    tn = calcTN(conf_mat, \"SLIP\")\n",
    "    fn = calcFN(conf_mat, \"SLIP\")\n",
    "    precision = round(calcPrecision(tp, fp), 3)\n",
    "    recall = round(calcRecall(tp, fn), 3)\n",
    "    f1 = round(calcF1(tp, fp, fn), 3)\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(fp,tp,fn,tn,precision,recall,f1))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for model_index in range(0, len(models)):\n",
    "    assigned_labels = compareLabels(\n",
    "        model_index,\n",
    "        error_noaps_embeddings,\n",
    "        error_noaps_sentences,\n",
    "        type_embeddings,\n",
    "        type_sentences,\n",
    "        type_labels\n",
    "    )\n",
    "    conf_mat = confusionMatrix(assigned_labels, error_noaps_labels)\n",
    "    # Lapses\n",
    "    tp = calcTP(conf_mat, \"LAPSE\")\n",
    "    fp = calcFP(conf_mat, \"LAPSE\")\n",
    "    tn = calcTN(conf_mat, \"LAPSE\")\n",
    "    fn = calcFN(conf_mat, \"LAPSE\")\n",
    "    precision = round(calcPrecision(tp, fp), 3)\n",
    "    recall = round(calcRecall(tp, fn), 3)\n",
    "    f1 = round(calcF1(tp, fp, fn), 3)\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(fp,tp,fn,tn,precision,recall,f1))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for model_index in range(0, len(models)):\n",
    "    assigned_labels = compareLabels(\n",
    "        model_index,\n",
    "        error_noaps_embeddings,\n",
    "        error_noaps_sentences,\n",
    "        type_embeddings,\n",
    "        type_sentences,\n",
    "        type_labels\n",
    "    )\n",
    "    conf_mat = confusionMatrix(assigned_labels, error_noaps_labels)\n",
    "    # Mistakes\n",
    "    tp = calcTP(conf_mat, \"MISTAKE\")\n",
    "    fp = calcFP(conf_mat, \"MISTAKE\")\n",
    "    tn = calcTN(conf_mat, \"MISTAKE\")\n",
    "    fn = calcFN(conf_mat, \"MISTAKE\")\n",
    "    precision = round(calcPrecision(tp, fp), 3)\n",
    "    recall = round(calcRecall(tp, fn), 3)\n",
    "    f1 = round(calcF1(tp, fp, fn), 3)\n",
    "    print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(fp,tp,fn,tn,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549b6df",
   "metadata": {},
   "source": [
    "# Single Class\n",
    "\n",
    "This section runs single class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c77e72",
   "metadata": {},
   "source": [
    "## Compute Embeddings & Cosine Similarity\n",
    "\n",
    "This code block computes embeddings for our data. Change `cleantext=True` to `cleantext=False` to run the experiment without preprocessing. This takes a few minutes to run with 16 CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487400cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEmbeddings(models, data, cleantext=True):\n",
    "    if cleantext:\n",
    "        sentences = [cleanup(d) for d in data]\n",
    "    else:\n",
    "        sentences = data\n",
    "    embeddings = list()\n",
    "    for model in models:\n",
    "        embeddings.append(model[1].encode(sentences, convert_to_tensor=True))\n",
    "        \n",
    "    return embeddings\n",
    "\n",
    "error_labels_slips = [\"SLIP\" if e[2].startswith(\"S\") else \"NOPE\" for e in errors]\n",
    "type_labels_slips = [\"SLIP\", \"NOPE\"]\n",
    "type_sents_slips = [type_sentences[0], type_sentences[1] + \" \" + type_sentences[2]]\n",
    "type_embeddings_slips = computeEmbeddings(models, type_sents_slips)\n",
    "\n",
    "error_labels_lapses = [\"LAPSE\" if e[2].startswith(\"L\") else \"NOPE\" for e in errors]\n",
    "type_labels_lapses = [\"LAPSE\", \"NOPE\"]\n",
    "type_sents_lapses = [type_sentences[1], type_sentences[0] + \" \" + type_sentences[2]]\n",
    "type_embeddings_lapses = computeEmbeddings(models, type_sents_lapses)\n",
    "\n",
    "error_labels_mistakes = [\"MISTAKE\" if e[2].startswith(\"M\") else \"NOPE\" for e in errors]\n",
    "type_labels_mistakes = [\"MISTAKE\", \"NOPE\"]\n",
    "type_sents_mistakes = [type_sentences[2], type_sentences[0] + \" \" + type_sentences[1]]\n",
    "type_embeddings_mistakes = computeEmbeddings(models, type_sents_mistakes)\n",
    "\n",
    "error_noaps_labels_slips = [\"SLIP\" if e[2].startswith(\"S\") else \"NOPE\" for e in errors_noaps]\n",
    "error_noaps_labels_lapses = [\"LAPSE\" if e[2].startswith(\"L\") else \"NOPE\" for e in errors_noaps]\n",
    "error_noaps_labels_mistakes = [\"MISTAKE\" if e[2].startswith(\"M\") else \"NOPE\" for e in errors_noaps]\n",
    "\n",
    "def compareLabels(model_index, err_embeddings, err_sentences, label_embeddings, label_sentences, labels):\n",
    "    assigned_labels = list()\n",
    "    for i in range(0, len(err_embeddings[model_index])):\n",
    "        cosine_scores = list()\n",
    "        for j in range(0, len(label_embeddings[model_index])):\n",
    "            # Compute cosine similarity between a single error sentence and a single label sentence\n",
    "            cosine_scores.append(util.cos_sim(\n",
    "                err_embeddings[model_index][i],\n",
    "                label_embeddings[model_index][j]\n",
    "            ))\n",
    "        \n",
    "        max_index = -999\n",
    "        max_value = -999\n",
    "        for k in range(0, len(cosine_scores)):\n",
    "            if cosine_scores[k] >= max_value:\n",
    "                max_value = cosine_scores[k]\n",
    "                max_index = k\n",
    "                \n",
    "        assigned_labels.append(labels[max_index])\n",
    "        \n",
    "    return assigned_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f390c",
   "metadata": {},
   "source": [
    "## Confusion Matrix w/ Apologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import math\n",
    "\n",
    "def confusionMatrix(assigned_labels, err_labels):\n",
    "    conf_mat = [\n",
    "        [0, 0], #Assigned-Actual: NOPE-NOPE, NOPE-Target      TN, FP\n",
    "        [0, 0]  #Assigned-Actual: Target-NOPE, Target-Target  FN, TP\n",
    "    ]\n",
    "    for i in range(0, len(err_labels)):\n",
    "        #print(i)\n",
    "        if err_labels[i] in [\"SLIP\", \"LAPSE\", \"MISTAKE\"]:\n",
    "            if assigned_labels[i] == err_labels[i]: #TP\n",
    "                conf_mat[1][1] += 1\n",
    "            else: #FN\n",
    "                conf_mat[1][0] += 1\n",
    "        elif err_labels[i] == \"NOPE\":\n",
    "            if assigned_labels[i] == err_labels[i]: #TN\n",
    "                conf_mat[0][0] += 1\n",
    "            else: #FP\n",
    "                conf_mat[0][1] += 1\n",
    "                \n",
    "    return conf_mat\n",
    "    \n",
    "def calcTP(conf_mat):\n",
    "    return conf_mat[1][1]\n",
    "\n",
    "def calcTN(conf_mat):\n",
    "    return conf_mat[0][0]\n",
    "\n",
    "def calcFP(conf_mat):\n",
    "    return conf_mat[0][1]\n",
    "\n",
    "def calcFN(conf_mat):\n",
    "    return conf_mat[1][0]\n",
    "    \n",
    "def calcPrecision(tp, fp):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def calcRecall(tp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def calcF1(tp, fp, fn):\n",
    "    return (2 * tp) / ((2 * tp) + fp + fn)\n",
    "\n",
    "def printConfusion(type_labels, err_labels, type_embs):\n",
    "    for model_index in range(0, len(models)):\n",
    "        assigned_labels = compareLabels(\n",
    "            model_index,\n",
    "            error_embeddings,\n",
    "            error_sentences,\n",
    "            type_embs,\n",
    "            type_sentences,\n",
    "            type_labels\n",
    "        )\n",
    "        conf_mat = confusionMatrix(assigned_labels, err_labels)\n",
    "        tp = calcTP(conf_mat)\n",
    "        fp = calcFP(conf_mat)\n",
    "        tn = calcTN(conf_mat)\n",
    "        fn = calcFN(conf_mat)\n",
    "        precision = round(calcPrecision(tp, fp), 3)\n",
    "        recall = round(calcRecall(tp, fn), 3)\n",
    "        f1 = round(calcF1(tp, fp, fn), 3)\n",
    "        print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(fp,tp,fn,tn,precision,recall,f1))\n",
    "\n",
    "printConfusion(type_labels_slips, error_labels_slips, type_embeddings_slips)\n",
    "print(\"\\n\")\n",
    "printConfusion(type_labels_lapses, error_labels_lapses, type_embeddings_lapses)\n",
    "print(\"\\n\")\n",
    "printConfusion(type_labels_mistakes, error_labels_mistakes, type_embeddings_mistakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed8fe90",
   "metadata": {},
   "source": [
    "## Confusion Matrix w/o Apologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0113f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "printConfusion(type_labels_slips, error_noaps_labels_slips, type_embeddings_slips)\n",
    "print(\"\\n\")\n",
    "printConfusion(type_labels_lapses, error_noaps_labels_lapses, type_embeddings_lapses)\n",
    "print(\"\\n\")\n",
    "printConfusion(type_labels_mistakes, error_noaps_labels_mistakes, type_embeddings_mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e34b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
